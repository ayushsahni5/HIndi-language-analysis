{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89957148",
   "metadata": {},
   "source": [
    "# 50 dimensional datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cfb71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.942607  ,  4.712879  , -5.7140045 ,  0.55029386,  8.697145  ,\n",
       "       -0.62258464,  1.97302   , -1.268698  ,  3.4255142 ,  3.5539782 ,\n",
       "       -8.642667  , -0.3361942 , -4.884162  ,  2.115304  ,  4.4939365 ,\n",
       "       -5.9335356 ,  2.532784  , -1.8532956 , -6.5794635 ,  3.0885158 ,\n",
       "       -2.2660308 ,  5.9763994 ,  1.8325341 , -2.025967  ,  8.1976    ,\n",
       "       -5.708584  ,  5.544921  , -0.22625978,  1.4576306 ,  3.8713539 ,\n",
       "        0.2907759 ,  2.6366081 , -2.999828  ,  0.7575537 , -3.6977448 ,\n",
       "       -6.483401  ,  0.8275771 ,  2.50695   ,  5.0593953 , -0.36954632,\n",
       "        7.744557  ,  2.202316  , -5.6128626 , -9.076401  , -1.724385  ,\n",
       "       -4.7248015 ,  9.151063  , -0.620149  ,  1.2605891 , -4.237625  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.load('hi/50/cbow/hi-d50-m2-cbow.model.wv.vectors.npy')\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe88a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33432856, -0.11202984, -0.2273171 ,  0.00921214,  0.23321326,\n",
       "        0.30691537,  0.18482019,  0.33345616, -0.03376731, -0.27710047,\n",
       "        0.10974217, -0.30162805,  0.10818107,  0.10074595, -1.054676  ,\n",
       "       -0.18795669, -0.35376957,  0.25867808,  0.31988895, -0.07906449,\n",
       "       -0.11058381, -0.05605265, -0.02893511, -0.13686505,  0.00372096,\n",
       "        0.44637656, -0.10839505, -0.53790563,  0.3298923 ,  0.00932342,\n",
       "        0.21710464,  0.35197288,  0.6207428 , -0.38095134,  0.28627953,\n",
       "        0.1006621 , -0.12758052,  0.32434115, -0.5287443 ,  0.2812715 ,\n",
       "        0.39222348, -0.28949073, -0.452456  , -0.530809  ,  0.6876619 ,\n",
       "        0.3638305 ,  0.12806542, -0.3298642 ,  0.38700515,  0.26806068],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.load('hi/50/cbow/hi-d50-m2-cbow.model.trainables.syn1neg.npy')\n",
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ded9da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "cbow_model = Word2Vec.load(\"hi/50/cbow/hi-d50-m2-cbow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ad0d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.942607  ,  4.712879  , -5.7140045 ,  0.55029386,  8.697145  ,\n",
       "       -0.62258464,  1.97302   , -1.268698  ,  3.4255142 ,  3.5539782 ,\n",
       "       -8.642667  , -0.3361942 , -4.884162  ,  2.115304  ,  4.4939365 ,\n",
       "       -5.9335356 ,  2.532784  , -1.8532956 , -6.5794635 ,  3.0885158 ,\n",
       "       -2.2660308 ,  5.9763994 ,  1.8325341 , -2.025967  ,  8.1976    ,\n",
       "       -5.708584  ,  5.544921  , -0.22625978,  1.4576306 ,  3.8713539 ,\n",
       "        0.2907759 ,  2.6366081 , -2.999828  ,  0.7575537 , -3.6977448 ,\n",
       "       -6.483401  ,  0.8275771 ,  2.50695   ,  5.0593953 , -0.36954632,\n",
       "        7.744557  ,  2.202316  , -5.6128626 , -9.076401  , -1.724385  ,\n",
       "       -4.7248015 ,  9.151063  , -0.620149  ,  1.2605891 , -4.237625  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.wv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ddab7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_similarity(a,b):\n",
    "    len_a=np.linalg.norm(a,ord=2)\n",
    "    len_b=np.linalg.norm(b,ord=2)\n",
    "    return np.dot(a,b)/(len_a * len_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04e97627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sim_file=open('Word similarity/hindi.txt','r',encoding='utf8')\n",
    "list_w1=[]\n",
    "list_w2=[]\n",
    "list_g_truth=[]\n",
    "for line in sim_file:\n",
    "    #print(line)\n",
    "    temp=line.split(',')\n",
    "    #print(temp[2])\n",
    "    list_w1.append(temp[0])\n",
    "    list_w2.append(temp[1])\n",
    "    temp[2]=re.sub('\\n','',temp[2])\n",
    "    temp[2]=float(temp[2])\n",
    "    #print(type(temp[2]))\n",
    "    list_g_truth.append(temp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6197d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_g_truth[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aac016",
   "metadata": {},
   "source": [
    "# CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb8319",
   "metadata": {},
   "source": [
    "## Threshold=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c1dd67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "threshold=4\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-cbow-4.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38268c0a",
   "metadata": {},
   "source": [
    "## Threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceff738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5692307692307692\n"
     ]
    }
   ],
   "source": [
    "threshold=5\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-cbow-5.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad44bf",
   "metadata": {},
   "source": [
    "## Threshold=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc3e999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5076923076923077\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-cbow-6.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf12fb07",
   "metadata": {},
   "source": [
    "## Threshold=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8bdae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5538461538461539\n"
     ]
    }
   ],
   "source": [
    "threshold=7\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-cbow-7.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf84c40",
   "metadata": {},
   "source": [
    "## Threshold=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "435787fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7846153846153846\n"
     ]
    }
   ],
   "source": [
    "threshold=8\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-cbow-8.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d302f",
   "metadata": {},
   "source": [
    "# Skip gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1779a76",
   "metadata": {},
   "source": [
    "## Threshold=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa7efc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_model=Word2Vec.load(\"hi/50/sg/hi-d50-m2-sg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7252964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "threshold=4\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-skipgram-4.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d635b4",
   "metadata": {},
   "source": [
    "## Threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c65b5b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5692307692307692\n"
     ]
    }
   ],
   "source": [
    "threshold=5\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-skipgram-5.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66256d5",
   "metadata": {},
   "source": [
    "## Threshold=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "befefbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5076923076923077\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-skipgram-6.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45593923",
   "metadata": {},
   "source": [
    "## Threshold=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5fd52c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5538461538461539\n"
     ]
    }
   ],
   "source": [
    "threshold=7\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-skipgram-7.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe4563",
   "metadata": {},
   "source": [
    "## Threshold=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1ec8e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7846153846153846\n"
     ]
    }
   ],
   "source": [
    "threshold=8\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-skipgram-8.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d16586",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daed01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "ft_model=FastText.load('hi/50/fasttext/hi-d50-m2-fasttext.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2851eb",
   "metadata": {},
   "source": [
    "## Threshold=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96d94003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "threshold=4\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-fasttext-4.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca06aeb",
   "metadata": {},
   "source": [
    "## Threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56b85c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5692307692307692\n"
     ]
    }
   ],
   "source": [
    "threshold=5\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-fasttext-5.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494458ab",
   "metadata": {},
   "source": [
    "## Threshold=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d21c5ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5076923076923077\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-fasttext-6.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1242c",
   "metadata": {},
   "source": [
    "## Threshold=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fd2e751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5538461538461539\n"
     ]
    }
   ],
   "source": [
    "threshold=7\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-fasttext-7.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb870aba",
   "metadata": {},
   "source": [
    "## Threshold=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07ba50c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7846153846153846\n"
     ]
    }
   ],
   "source": [
    "threshold=8\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-fasttext-8.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2f99e6",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56483e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=open('hi/50/glove/hi-d50-glove.txt','r',encoding='utf8',errors='ignore')\n",
    "glove_dict={}\n",
    "for lines in a:\n",
    "    lines=lines.split()\n",
    "    key=lines[0]\n",
    "    val=lines[1:]\n",
    "    val=[float(element) for element in val]\n",
    "    glove_dict[key]=np.array(val)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdf98601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "threshold=4\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-glove-4.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e45ea220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5692307692307692\n"
     ]
    }
   ],
   "source": [
    "threshold=5\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-glove-5.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25365765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5076923076923077\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-glove-6.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cae416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5538461538461539\n"
     ]
    }
   ],
   "source": [
    "threshold=7\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-glove-7.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8c2ba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7846153846153846\n"
     ]
    }
   ],
   "source": [
    "threshold=8\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('50-glove-8.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cedfa8",
   "metadata": {},
   "source": [
    "# 100 dimensional datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3b3d685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cbow_model = Word2Vec.load(\"hi/100/cbow/hi-d100-m2-cbow.model\")\n",
    "\n",
    "threshold=4\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-cbow-4.csv')\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5578bd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49230769230769234\n"
     ]
    }
   ],
   "source": [
    "threshold=5\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-cbow-5.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9dabe00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4461538461538462\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-cbow-6.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab389210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5230769230769231\n"
     ]
    }
   ],
   "source": [
    "threshold=7\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-cbow-7.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a027dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8307692307692308\n"
     ]
    }
   ],
   "source": [
    "threshold=8\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-cbow-8.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d4677c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_model=Word2Vec.load(\"hi/100/sg/hi-d100-m2-sg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6811143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "threshold=4\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-skipgram-4.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11eed77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49230769230769234\n"
     ]
    }
   ],
   "source": [
    "threshold=5\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-skipgram-5.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dda15efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4461538461538462\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-skipgram-6.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "969a32e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5230769230769231\n"
     ]
    }
   ],
   "source": [
    "threshold=7\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-skipgram-7.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "804b54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8307692307692308\n"
     ]
    }
   ],
   "source": [
    "threshold=8\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-skipgram-8.csv')\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fddff6",
   "metadata": {},
   "source": [
    "## fast text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dbf9b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "ft_model=FastText.load('hi/100/fasttext/hi-d100-m2-fasttext.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d63c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "threshold=4\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-fasttext-4.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3b9536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49230769230769234\n"
     ]
    }
   ],
   "source": [
    "threshold=5\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-fasttext-5.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6fe9a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4461538461538462\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-fasttext-6.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ac595c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5230769230769231\n"
     ]
    }
   ],
   "source": [
    "threshold=7\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-fasttext-7.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2d43a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8307692307692308\n"
     ]
    }
   ],
   "source": [
    "threshold=8\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-fasttext-8.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c61634b",
   "metadata": {},
   "source": [
    "## glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db660d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=open('hi/100/glove/hi-d100-glove.txt','r',encoding='utf8',errors='ignore')\n",
    "glove_dict={}\n",
    "for lines in a:\n",
    "    lines=lines.split()\n",
    "    key=lines[0]\n",
    "    val=lines[1:]\n",
    "    val=[float(element) for element in val]\n",
    "    glove_dict[key]=np.array(val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6c9e199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "threshold=4\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-glove-4.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78de7591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49230769230769234\n"
     ]
    }
   ],
   "source": [
    "threshold=5\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-glove-5.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa31e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4461538461538462\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-glove-6.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "844cc244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5230769230769231\n"
     ]
    }
   ],
   "source": [
    "threshold=7\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-glove-7.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9391acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8307692307692308\n"
     ]
    }
   ],
   "source": [
    "threshold=8\n",
    "correct_pred=0\n",
    "cosine_score=[]\n",
    "label=[]\n",
    "for i in range(len(list_w1)):\n",
    "    w1=cbow_model.wv[list_w1[i]]\n",
    "    w2=cbow_model.wv[list_w2[i]]\n",
    "    similarity_pred=cosine_similarity(w1,w2)\n",
    "    cosine_score.append(similarity_pred)\n",
    "    if similarity_pred*10<threshold and list_g_truth[i]<threshold or similarity_pred*10>=threshold and list_g_truth[i]>=threshold:\n",
    "        label.append(1)\n",
    "        correct_pred+=1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        \n",
    "accuracy=correct_pred/len(list_w1)\n",
    "my_dict={'Word1':list_w1,'Word2':list_w2,'Similarity Score':cosine_score,'Ground Truth':list_g_truth,'Label':label}\n",
    "df=pd.DataFrame(my_dict)\n",
    "#filenaming convention= dimensions-modelname-threshold.csv\n",
    "df.to_csv('100-glove-8.csv')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5904c2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
